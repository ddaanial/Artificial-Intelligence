{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XubLQR6NBDO"
   },
   "source": [
    "<div align=center>\n",
    "\t\t\n",
    "<p></p>\n",
    "<p></p>\n",
    "<font size=5>\n",
    "In the Name of God\n",
    "<font/>\n",
    " <p></p>\n",
    " <br/>\n",
    "\t\t<div align=center>\n",
    "\t\t    <size=6>\n",
    "\t\t\t    <br />\n",
    "Practical Assignment 4 - part 1\n",
    "              <font color=blue size=6>\n",
    "            \t<br/>\n",
    "              Naive Bayes Classifier\n",
    "\t\t\t</font>\n",
    "    <br/>\n",
    "    <br/>\n",
    " </div>\n",
    "<hr/>\n",
    "Artifical Intelligence - Dr. GholamReza GhassemSani\n",
    "</font>\n",
    "  <p></p>\n",
    " <br/>\n",
    "Sharif University of Technology\n",
    "<p></p>\n",
    "Spring 2022\n",
    "\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<font size=4 color=red>\n",
    " </font>\n",
    "                <br/>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NY0TuS_eNH9W"
   },
   "source": [
    "**Due date: 19/4/1401 (at 11:59pm)**<br>\n",
    "You are free to collaborate but solutions must be written up individually.\n",
    "Collaborators **must** be acknowledged.<br>\n",
    "Submissions with more than 100 hours delay will not be graded.<br>Submissions with less than\n",
    "50 hours delay will be penalized by the following rule:<br>\n",
    "**Penalized mark = M * (100 – D) / 100** <br>\n",
    "Where M = the mark achieved from your solution and D is number of hours passed the\n",
    "deadline. Submissions with 50 < X ≤ 100 hours delay will be penalized by P.M. = M * 0.5.<br>\n",
    "Submit your answers on quera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xr0SFBmgNLFX"
   },
   "source": [
    "student_number = 400211546\n",
    "Name = Danial\n",
    "Last_Name = Ahangarani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAlQQZzFNNap"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ag0nI_YUNRpA"
   },
   "source": [
    "### In this assignment, you are going to learn about the Naive Bayes algorithm, including how it works and how to implement it from scratch on a given dataset. Hence you are not allowed to use scikit-learn for implementing NB.\n",
    "### You will use the [SentiPers](https://github.com/phosseini/SentiPers) dataset for this assignment, which is a sentiment analysis corpus for Persian.\n",
    "### Note that F1-Score will be used to evaluate your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naxLbFBVYtX-"
   },
   "source": [
    "# SentiPers Dateset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVCeQJQQYzUB"
   },
   "source": [
    "### You can download the dataset from this link:\n",
    "https://github.com/phosseini/SentiPers/blob/master/data/sentipers.xlsx\n",
    "### The SentiPers dataset involves polarity of some sentences. There are more than 15,500 unique sentences with polarity labels in the range of [\"-2\", \"-1\", \"0\", \"+1\", \"+2\"] with -2 being very negative, +2 being very positive, and 0 being neutral.\n",
    "### In this step, you have to import the necessary dependencies, download the dataset and do some initial preprocessing on the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5o4oxdT1ezKO"
   },
   "source": [
    "### Do not forget the following items: \n",
    "\n",
    "1.   Download the dataset and show some of its rows.\n",
    "2.   Briefly describe the dataset. Check that if it has any Nan or duplicated values.\n",
    "3.   Describe the polarity column. Show its unique values and count each one.\n",
    "4.   Ignore all sentences with 0 as their polarity label. Also, assume that there are only two positive and negative classes, +1 and +2 as positive and -1 and -2 as negative.\n",
    "5.   (Optional) Text preprocessing is the very first step of NLP projects. You can either implement this part, or use libraries ([hazm](https://github.com/sobhe/hazm), [parsivar](https://github.com/ICTRC/Parsivar)). Use appropriate preprocessing steps based on the dataset.\n",
    "6.   Report the corpus's total number of sentences and words. Also, print the ten most seen words with their frequency.\n",
    "7.   Note that the dataset is imbalanced (the positive and negative classes are not represented equally). Explain how this problem can affect the accuracy and what your solution is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LIBzapV8U7jr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yH02bdPyHFdV"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/phosseini/SentiPers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dnMZ4bkfskPM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sid</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>rev-1</td>\n",
       "      <td>اینک قصد داریم پرینتر دیگری از پرینترهای لیزری...</td>\n",
       "      <td>0</td>\n",
       "      <td>data/main/HP LaserJet M1132.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rev-2</td>\n",
       "      <td>پرینتری چند کاره از رده‌ی Entry Level یا سطح م...</td>\n",
       "      <td>0</td>\n",
       "      <td>data/main/HP LaserJet M1132.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rev-3</td>\n",
       "      <td>به هر صورت اکنون ما در دنیایی زندگی می‌کنیم،  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>data/main/HP LaserJet M1132.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rev-4</td>\n",
       "      <td>به صورتی که توانایی کپی کردن،  اسکن،  فکس،  پر...</td>\n",
       "      <td>0</td>\n",
       "      <td>data/main/HP LaserJet M1132.xml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rev-5</td>\n",
       "      <td>به هر صورت معمولا چیزی که بیشتر کاربران از پری...</td>\n",
       "      <td>2</td>\n",
       "      <td>data/main/HP LaserJet M1132.xml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    sid                                               text  polarity  \\\n",
       "0      0  rev-1  اینک قصد داریم پرینتر دیگری از پرینترهای لیزری...         0   \n",
       "1      1  rev-2  پرینتری چند کاره از رده‌ی Entry Level یا سطح م...         0   \n",
       "2      2  rev-3  به هر صورت اکنون ما در دنیایی زندگی می‌کنیم،  ...         0   \n",
       "3      3  rev-4  به صورتی که توانایی کپی کردن،  اسکن،  فکس،  پر...         0   \n",
       "4      4  rev-5  به هر صورت معمولا چیزی که بیشتر کاربران از پری...         2   \n",
       "\n",
       "                              file  \n",
       "0  data/main/HP LaserJet M1132.xml  \n",
       "1  data/main/HP LaserJet M1132.xml  \n",
       "2  data/main/HP LaserJet M1132.xml  \n",
       "3  data/main/HP LaserJet M1132.xml  \n",
       "4  data/main/HP LaserJet M1132.xml  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('sentipers.xlsx')\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#دیتاست شامل نظرات کاربران دیجی کالا بر محصولات و برچسبی است\n",
    "#که بر هر نظر بر یک محصول، در غالب ستون پولاریتی زده شده است\n",
    "# .که از بازه دو مثبت تا دو منفی است\n",
    "#\n",
    "#ارزش دو مثبت در ستون پولاریتی به مثبت ترین نظرات، ارزش یک مثبت \n",
    "#به نظرات کمتر مثبت، ارزش صفر به نظرات خنثی و همین طور ارزش  \n",
    "#یک منفی و دو منفی به بسته به میزان منفی بودن یک نظر کاربر بر یک\n",
    "#.محصول داده شده است"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iwNQXxOnpnlD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data set has null values: False\n",
      "data set has duplicated values: False\n",
      "*************************************\n",
      "data set has 212 with -2 polarity.\n",
      "data set has 1574 with -1 polarity.\n",
      "data set has 5938 with 0 polarity.\n",
      "data set has 5019 with 1 polarity.\n",
      "data set has 2940 with 2 polarity.\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#Checking if dataset has duplicated values or null values.\n",
    "null_check = df.isnull().values.any()\n",
    "dup_check = df.duplicated().any()\n",
    "print(f\"data set has null values: {null_check}\")\n",
    "print(f\"data set has duplicated values: {dup_check}\")\n",
    "print(\"*************************************\")\n",
    "\n",
    "#Showing polarity unique values and counting each one.\n",
    "for i in sorted(pd.unique(df['polarity'])):\n",
    "    print(f\"data set has {len(df[df['polarity'] == i])} with {i} polarity.\")\n",
    "\n",
    "#Ignoring polarity = 0 and merging classes.\n",
    "df = df[df.polarity != 0]\n",
    "df['P/N'] = np.where((df['polarity']==1) | (df['polarity']==2) , 'P', 'N')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing and tokenizing using parsivar library.\n",
    "from parsivar import *\n",
    "normalizer = Normalizer()\n",
    "df_normalized_text = []\n",
    "df_tokenized_text = []\n",
    "for t in df['text']:\n",
    "    df_normalized_text.append(normalizer.normalize(t))\n",
    "tokenizer = Tokenizer()\n",
    "for t in df_normalized_text:\n",
    "    df_tokenized_text.append(tokenizer.tokenize_words(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences: 10494\n",
      "number of words: 226633\n",
      "\n",
      "\n",
      "ten most seen words in corpus:\n",
      "1: .\n",
      "2: و\n",
      "3: به\n",
      "4: که\n",
      "5: این\n",
      "6: از\n",
      "7: در\n",
      "8: ،\n",
      "9: با\n",
      "10: است\n"
     ]
    }
   ],
   "source": [
    "#carpus sentences and words. \n",
    "sentences = []\n",
    "sum_sen = 0\n",
    "for sen in df_normalized_text:\n",
    "    sentences.append(tokenizer.tokenize_sentences(sen))\n",
    "for s in sentences:\n",
    "    sum_sen += len(s)\n",
    "print(f\"number of sentences: {sum_sen}\")\n",
    "word = 0\n",
    "all_word = []\n",
    "for w in df_tokenized_text:\n",
    "    word += len(w)\n",
    "    all_word += w\n",
    "print(f\"number of words: {word}\")\n",
    "\n",
    "c = Counter(all_word)\n",
    "ten_most = c.most_common(10) \n",
    "print(\"\\n\")\n",
    "print(\"ten most seen words in corpus:\")\n",
    "for t in range(len(ten_most)):\n",
    "    print(f\"{t+1}: {ten_most[t][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1786 neg and 7959 pos.\n",
    "#دیتاست بالانس نیست و روی داده تست\n",
    "#نظر + تقریبا چهار برابر نظر - است\n",
    "#حتی اگر مدل نتواند هیچ نظر منفی را پیش بینی کند باز هم\n",
    "#Accuracy \n",
    "#هشتاد در صد است چون دیتا شامل همین درصد نظر مثبت است\n",
    "#پس\n",
    "#Accuracy \n",
    "#معیار خوبی برای دیتای غیر بالانس نیست\n",
    "# we can use F1 Score, which is a function of Recall and Precision.\n",
    "#اما من در اینجا با \n",
    "#Resampling\n",
    "#تعداد سمپل های گروه مثبت و منفی را برابر در نظر گرفتم"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parsivar import *\n",
    "ddf = pd.read_excel('sentipers.xlsx')\n",
    "ddf = ddf[ddf.polarity != 0]\n",
    "ddf['P/N'] = np.where((ddf['polarity']==1) | (ddf['polarity']==2) , 'P', 'N')\n",
    "del ddf['index']\n",
    "del ddf['sid']\n",
    "del ddf['polarity']\n",
    "del ddf['file']\n",
    "\n",
    "ddf = ddf.sample(frac=1,random_state=4)\n",
    "ndf = ddf.loc[ddf['P/N'] == 'N']\n",
    "pdf = ddf.loc[ddf['P/N'] == 'P'].sample(n=len(ndf),random_state=42)\n",
    "ddf = pd.concat([pdf, ndf])\n",
    "ddf = ddf.sample(frac=1,random_state=4)\n",
    "\n",
    "data_randomized = ddf.sample(frac=1, random_state=1)\n",
    "training_test_index = round(len(data_randomized)*.75)\n",
    "\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "normalizer = Normalizer()\n",
    "temp1 = []\n",
    "for t in training_set['text']:\n",
    "    temp1.append(normalizer.normalize(t))\n",
    "training_set['text'] = temp1\n",
    "tokenizer = Tokenizer()\n",
    "temp2 = []\n",
    "for t in training_set['text']:\n",
    "    temp2.append(tokenizer.tokenize_words(t))\n",
    "training_set['text'] = temp2\n",
    "\n",
    "vocabulary = []\n",
    "for text in training_set['text']:\n",
    "    for word in text:\n",
    "        vocabulary.append(word)\n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "taJ5mVoNn95A"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCT1UhdXoCTG"
   },
   "source": [
    "### In this step, you must extract good features from the raw text and prepare it for the Naive Bayes algorithm. A simple way is to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text.\n",
    "### Note that extracting good and meaningful features greatly affects the model and can get you extra credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NvEktvIPsEN4"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "word_counts_per_text = {unique_word: [0] * len(training_set['text']) for unique_word in vocabulary}\n",
    "for index, t in enumerate(training_set['text']):\n",
    "    for word in t:\n",
    "        word_counts_per_text[word][index] += 1\n",
    "word_counts = pd.DataFrame(word_counts_per_text)\n",
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDFbbXqPsL1K"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vlb1vkeKsQql"
   },
   "source": [
    "### Implement Naive Bayes from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "whBxjHoCs4mB"
   },
   "outputs": [],
   "source": [
    "# Isolating p and n\n",
    "positives = training_set_clean[training_set_clean['P/N'] == 'P']\n",
    "negetives = training_set_clean[training_set_clean['P/N'] == 'N']\n",
    "\n",
    "# P(positive) and P(negetive)\n",
    "p_p = len(positives) / len(training_set_clean)\n",
    "p_n = len(negetives) / len(training_set_clean)\n",
    "\n",
    "# N_P\n",
    "n_words_per_pos = positives['P/N'].apply(len)\n",
    "n_p = n_words_per_pos.sum()\n",
    "\n",
    "# N_N\n",
    "n_words_per_neg = negetives['P/N'].apply(len)\n",
    "n_n = n_words_per_neg.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "# Initiate parameters\n",
    "parameters_pos = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_neg = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_pos = positives[word].sum() \n",
    "    p_word_given_pos = (n_word_given_pos + alpha) / (n_p + alpha*n_vocabulary)\n",
    "    parameters_pos[word] = p_word_given_pos\n",
    "\n",
    "    n_word_given_neg = negetives[word].sum() \n",
    "    p_word_given_neg = (n_word_given_neg + alpha) / (n_n + alpha*n_vocabulary)\n",
    "    parameters_neg[word] = p_word_given_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    message = tokenizer.tokenize_words(normalizer.normalize(message))\n",
    "    p_pos_given_message = p_p\n",
    "    p_neg_given_message = p_n\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_pos:\n",
    "            p_pos_given_message *= parameters_pos[word]\n",
    "\n",
    "        if word in parameters_neg: \n",
    "             p_neg_given_message *= parameters_neg[word]\n",
    "\n",
    "    if p_neg_given_message > p_pos_given_message:\n",
    "        return 'N'\n",
    "\n",
    "    else:\n",
    "        return 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for t in test_set['text']:\n",
    "    l.append(classify(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hP45f0HuDa5"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv3KXnNfvKh1"
   },
   "source": [
    "### Your code will be evaluated by the F1 score. If your model predicts better than a random predictor, you will get the total score of this part. So explain what F1 score we get with a random predictor.\n",
    "\n",
    "### After beating the random predictor, you will get extra credit for improving your model due to your F1 score.\n",
    "\n",
    "### Use 75% of the data for the training and 25% for the testing set.\n",
    "\n",
    "### Do not forget to report the following items:\n",
    "\n",
    "1.   Accuracy\n",
    "2.   Precision\n",
    "3.   Recall\n",
    "4.   Confusion Matrix\n",
    "5.   F1 Score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nZv3Ws54ub6I"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ga6x1-Vu1Yo"
   },
   "outputs": [],
   "source": [
    "# TODO: Do not forget to extract features. You can also do this step after the train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "y5uHRFNmUjCm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.799552071668533\n",
      "precision: 0.8145539906103286\n",
      "recall: 0.7762863534675615\n",
      "F1: 0.7949599083619702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assigned Positive</th>\n",
       "      <th>Assigned Negetive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>347</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negetive</th>\n",
       "      <td>100</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Assigned Positive  Assigned Negetive\n",
       "True Positive                347                 79\n",
       "True Negetive                100                367"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_num = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "for a,b in zip(l,test_set['P/N']):\n",
    "    if a == b:\n",
    "         true_num += 1\n",
    "    if a == 'P' and b == 'P':\n",
    "        tp += 1\n",
    "    if a == 'P' and b == 'N':\n",
    "        fp += 1\n",
    "    if a == 'N' and b == 'P':\n",
    "        fn += 1\n",
    "    if a == 'N' and b == 'N':\n",
    "        tn += 1\n",
    "        \n",
    "accuracy = true_num/len(l)  \n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "F1 = (2*recall*precision)/(precision+recall)\n",
    "\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "print(f'F1: {F1}')\n",
    "c_m = [ (tp, fp) ,(fn, tn) ]\n",
    "confusion_matrix = pd.DataFrame(c_m, columns = ['Assigned Positive', 'Assigned Negetive'], index=['True Positive', 'True Negetive'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1CYe2xzvzO0"
   },
   "source": [
    "# scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H0zKvC5ov-zW"
   },
   "source": [
    "### Now use Scikit-learn and compare it with your model. You can use CountVectorizer for extracting features and MultinomialNB for the NB model. Feel free to use other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5mkO5UeUwxF4"
   },
   "outputs": [],
   "source": [
    "# Try not to change this cell.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "labels = df['P/N']\n",
    "X = df['text']\n",
    "x, x_test, y, y_test = train_test_split(X, labels, stratify=labels, test_size=0.25, random_state=42)\n",
    " \n",
    "# Create a Vectorizer Object\n",
    "vectorizer = CountVectorizer()\n",
    " \n",
    "vectorizer.fit(x)\n",
    " \n",
    "# Encode the Document\n",
    "vector = vectorizer.transform(x)\n",
    "vector1 = vectorizer.transform(x_test)\n",
    "  \n",
    "clf = MultinomialNB()\n",
    "clf.fit(vector, y)\n",
    "\n",
    "S_pre = clf.predict(vector1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_num_S = 0\n",
    "tp_S = 0\n",
    "fp_S = 0\n",
    "fn_S = 0\n",
    "tn_S = 0\n",
    "for a,b in zip(S_pre,y_test):\n",
    "    if a == b:\n",
    "         true_num_S += 1\n",
    "    if a == 'P' and b == 'P':\n",
    "        tp_S += 1\n",
    "    if a == 'P' and b == 'N':\n",
    "        fp_S += 1\n",
    "    if a == 'N' and b == 'P':\n",
    "        fn_S += 1\n",
    "    if a == 'N' and b == 'N':\n",
    "        tn_S += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8395568321707017\n",
      "precision: 0.8853012048192771\n",
      "recall: 0.9231155778894472\n",
      "F1: 0.9038130381303813\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assigned Positive</th>\n",
       "      <th>Assigned Negetive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True Positive</th>\n",
       "      <td>1837</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negetive</th>\n",
       "      <td>153</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Assigned Positive  Assigned Negetive\n",
       "True Positive               1837                238\n",
       "True Negetive                153                209"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_S = true_num_S/len(S_pre)  \n",
    "precision_S = tp_S/(tp_S+fp_S)\n",
    "recall_S = tp_S/(tp_S+fn_S)\n",
    "F1_S = (2*recall_S*precision_S)/(precision_S+recall_S)\n",
    "\n",
    "print(f'accuracy: {accuracy_S}')\n",
    "print(f'precision: {precision_S}')\n",
    "print(f'recall: {recall_S}')\n",
    "print(f'F1: {F1_S}')\n",
    "c_m_S = [ (tp_S, fp_S) ,(fn_S, tn_S) ]\n",
    "confusion_matrix_S = pd.DataFrame(c_m_S, columns = ['Assigned Positive', 'Assigned Negetive'], index=['True Positive', 'True Negetive'])\n",
    "confusion_matrix_S"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PA4-part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
